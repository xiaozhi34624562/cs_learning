# 高性能的设计
## 无锁化
#### 串行无锁
在网络编程模型中，主线程（reactor）负责处理I/O事件，并将读的数据压入到队列中，工作线程从队列中取出数据，这种半同步/半异步模型需要对队列进行加锁。
无锁串行的形式，MainReactor accept一个新连接后，从众多的subReactor中选取一个注册， 通过创建一个Channel与I/O线程进行绑定，此后该连接的读写都在同一个线程执行，无需进行同步。
#### 结构无锁
利用硬件支持的原子操作可以实现无锁结构。在while循环里面使用CAS操作

## 零拷贝
数据在内核缓冲区和应用程序缓冲区直接的传出，并非指进程空间中的内存拷贝。拷贝过程：
1. 磁盘文件拷贝到内核缓冲区
2. 内核缓冲区到用户空间的应用程序
3. 从用户空间的应用程序到Socket缓冲区
4. 从Socket缓冲区到网络

1和4是DMA（Direct Memory Access），直接从存储器存取，快速传送数据的机制，即外部设备不通过CPU而直接与系统内存交换数据的接口技术。2和3是CPU拷贝

#### 内存映射
将用户空间的一段内存区域映射到内核空间，用户对这段内存区域的修改可以直接反映到内核空间，同样，内核空间对这段区域的修改也直接反映到用户空间，用户空间共享这个内核缓冲区。拷贝数据时从磁盘文件到内核缓冲区，然后倒Socket缓冲区，最后道网络。
#### 零拷贝
1. DMA将数据拷贝到DMA引擎的内核缓冲区
2. 将数据的位置和长度的信息的描述符加到socket缓冲区
3. DMA引擎直接将数据从内核缓冲区传递到协议引擎

消除了内核缓冲区和用户缓冲区之间的CPU拷贝，Linux中主要的零拷贝函数有sendfile、splice和tee等

## 序列化
数据传输和存储的基础
#### 分类
- 内置类型：编程语言内置支持的类型，如java的Serializable，与语言绑定，不具有通用性。
- 文本类型：一般是标准化的文本格式，如XML和JSON，支持跨平台，但是比较臃肿，网络传输占用带宽大
- 二进制类型：采取二进制编码，数据组织更佳紧凑，支持多语言和多平台，有Protocal Buffer/Thrify/MessagePack/FlatBuffer
#### 性能指标
- 序列化之后的字节大小
- 序列化和反序列化的速度
- CPU和内存消耗
Protobuf在序列化的速度伤和字节占比上都很好，FlatBuffer可能更好
#### 选型考量
- 性能
- 易用性，很多序列化框架都是支持List，Map的
- 通用性
- 扩展性

## 池子化
通过创建池子来提高对象复用
#### 内存池
malloc主要通过ptmalloc,  tcmalloc和jemalloc来实现，后两者的性能相对要好。redis和mysql都可以指定使用哪个malloc。
#### 线程池
线程池可以分类或者分组，不同的任务可以使用不同的线程组，可以进行隔离以免互相影响。对于分类，可以分为核心和非核心，核心线程池一直存在不会被回收，非核心可能对空闲一段时间后的线程进行回收，从而节省系统资源，等到需要时在按需创建放入池子中。
#### 连接池
常见的连接池有数据库连接池，redis连接池，tcp连接池等，主要涉及到以下几个问题：
- 初始化：启动时初始化和惰性初始化。启动初始化可以减少一些加锁操作，需要时可以直接使用，缺点是可能造成服务启动缓慢和启动后没有任务处理，造成资源浪费。惰性初始化，有需要的时候再去创建，有助于减少资源占用，但是如果面对突发的任务请求时，瞬间创建一堆连接可能造成系统响应慢或者响应失败。通常会采取启动即初始化的方式。
- 连接数目：连接数少导致任务处理慢，太多不但使任务处理慢还会消耗系统资源
- 连接取出：当连接池已经无可用连接时，是一直等待直到有可用链接，还是分配一个新的临时链接
- 连接放入：但连接使用完毕且连接池未满时，放入连接池，否则关闭。
- 连接检测：长时间空闲连接和失效连接需要关闭并且从连接池中移除，可以使用时检测和定期检测

#### 对象池
缓存一些对象，避免大量创建同一类型的对象，同时限制了实例的个数。

## 并发化
#### 请求并发
请求并发。将没有依赖关系的子任务并发化，还可以将同种请求进行批量合并，减少RPC调用的次数。
#### 请求冗余
同时向后端发送多个同样的请求，谁响应快就使用谁，其他的则丢弃，一般是用于初始化或者请求少的场景。

## 异步化
#### 调用异步化
遇到耗时的RPC调用或者任务处理时，常用的异步化方式如下：
- Callback：异步回调通富哦注册一个回调函数，然后发起异步任务，当任务执行完毕后会回调用户注册的回调函数，从而减少调用端等待时间，但是会造成代码分散难以维护，定位问题也比较难
- Future：当用户提交一个任务时，会立即先返回一个Future，然后任务异步执行，后续可以通过Future获取执行结果。
- CPS（Continuation-passing style)：可以对多个异步编程进行编排，组成更复杂的异步处理，并以同步的代码调用形式来实现异步效果。CPS 将后续的处理逻辑当作参数传递给 Then 并可以最终捕获异常，解决了异步回调代码散乱和异常跟踪难的问题，如Java 中的 CompletableFuture 。
#### 流程异步化
一个业务流程往往伴随着调用链路长、后置依赖多等特点，这会同时降低系统的可用性和并发处理能力。可以采用对非关键依赖进行异步化解决。如企鹅电竞开播服务，除了开播写节目存储以外，还需要将节目信息同步到神盾推荐平台、App 首页和二级页等。由于同步到外部都不是开播的关键逻辑且对一致性要求不是很高，可以对这些后置的同步操作进行异步化（MQ），写完存储即向 App 返回响应

## 缓存
#### 使用场景
空间换时间的技术，使用的场景如下：
- 一旦生成后基本不会变化的数据：如企鹅电竞的游戏列表，在后台创建一个游戏之后基本很少变化，可直接缓存整个游戏列表
- 读密集型或存在热点的数据：典型的就是各种 App 的首页，如企鹅电竞首页直播列表
- 计算代价大的数据：如企鹅电竞的 Top 热榜视频，如 7 天榜在每天凌晨根据各种指标计算好之后缓存排序列表
- 千人一面的数据：同样是企鹅电竞的 Top 热榜视频，除了缓存的整个排序列表，同时直接在进程内按页缓存了前 N 页数据组装后的最终回包结果

**不适用的场景**
- 读多写少，更新频繁
- 对数据一致性要求严格

#### 缓存分类
- 进程级缓存：缓存的数据直接在进程地址空间内，速度最快最简单的缓存方式。但是，进程空间小，重启时数据会丢失，通常用于缓存数据量不大的场景。
- 集中式缓存：缓存的数据集中在一台机器上，如共享缓存，如单机版的redis，memcache
- 分布式缓存：缓存的数据分布在多台机器上，通常使用特定算法（Hash)进行数据分片，将海量的缓存数据均匀分布在每个机器节点上，如Memcache的客户端分片，Codis代理分片，redis cluster集群分片
- 多级缓存：在系统中的不同层级进行数据缓存，以提高访问效率和减少对后端存储的冲击。

#### 使用模式
主要是Cache-Aside和Cache-As-SoR(system-of-record)，sor表示数据源，而cache是sor的复制集。
- Cache-Aside：旁路缓存。对于读，先从缓存中读数据，如果有命中没，则回源SoR读取并更新缓存；对于写，先写SoR，再写缓存。
- Cache-As-SoR:缓存即数据源，把cache当做SoR，所以读写都是针对Cache，然后Cache再将读写操作委托给SoR。
    - Read-Through：发生读操作的时候，先查询Cache，如果不命中，则由Cache回源到SoR，即存储端实现Cache-Aside而不是业务
    - Write-Through：穿透写模式。有业务先调用写操作，然后由Cache负责写缓存和SoR
    - Write-Behind：写回模式。发生写操作时只更新缓存并立即返回，然后异步写SoR，这样可以利用批量写来提高性能。
    
#### 回收策略
- 基于时间
- 基于容量
- 基于引用

如FIFO，LRU，LFU

#### 崩溃与修复
- 缓存穿透：大量使用不存在的key进行查询，缓存没有命中，请求都穿透到后端的存储上，导致后端压力过大或者被压垮
    - 设置空值或者默认值
    - 布隆过滤器
- 缓存雪崩：大量的缓存在一段时间内集体失效
    - 过期时间加上随机时间
    - 缓存实例宕机导致的，使用主从备份或者一致性哈希使少量失效
- 缓存热点：热点数据存在某一个实例上。
    - 生成多份缓存放在不同的节点上 

#### 缓存实践
- 动静分离
- 慎用大对象
- 过期设置
- 超时设置
- 缓存隔离：不同业务使用不同的key；核心业务与非核心业务使用不同的缓存实例进行物理隔离
- 失败降级：如果缓存部分失效或者失败，应该继续回源处理，不应该直接中断返回
- 容量控制:避免swap发生
- 监控告警

## 分片
将一个大数据集分散在更多的节点上，单点的读写负载也分散到多个节点上，同时还提高了扩展性和可用性

#### 分片策略
- 区间分片：基于一段连续关键字的分片，保持了排序，适合进行范围查找，减少了跨分片读写。但是，容易造成数据分布不均匀，如短位ID都是一些大主播。常见的还有按时间范围分片，则最近时间段的读写操作通常比很久以前的时间段频繁。
- 随机分片：按照一定的方式（hash取模）进行分片，这种方式数据分布比较均匀，不容易出现热点和并发瓶颈。但是，失去了有序相邻的特性，进行范围查询的时候，会像多个节点发起请求。
- 组合分片：采取以上两种方式的组合，通过多个键组成复合键，其中第一个键用于做hash随机，其余键用于进行区间排序。如直播平台以主播id+开播时间作为组合键，可以高效的查询某主播在某个时间段内的开播记录。社交场景中，微信朋友圈和微博等，用用户id+发布时间的组合找到用户某段时间的发表记录

#### 二级索引
二级索引通常用来加速特定值的查找，不能唯一标识一条记录，使用二级索引需要二次查找。如mysql中的辅助索引和ES倒排索引通过term找到文档
- 本地索引存储在与关键字相同的分区中，即索引和记录在同一个分区，这样对于写操作时，都在一个分区进行，不需要跨分区操作。但是对于读操作，需要聚合其他分区上的数据，如王者荣耀短视频为例，以视频vid作为关键索引，视频标签（五杀，三杀）作为二级索引，同一个分区只能找到分区内的五杀视频，所以当搜索五杀视频时需要遍历所有分区。
- 全局索引按索引值本身进行分区，与关键字独立，这样对于读取某个索引的数据时，都在一个分区里进行，而对于写操作，需要跨越多个分区，所有五杀的信息会放在一个分区里。

#### 路由策略
路由策略决定如何将数据请求发送到指定的节点。
- 客户端路由：客户端直接操作分片逻辑，感知分片和节点的分配关系，并直接连接到目标节点。Memcache就是采取这种方案，客户端存储了服务器列表。
- 代理层路由：客户端的请求发送到代理层，由其将请求转发到对应的数据节点上。如基于redis实现的分布式存储codis中的codis-proxy层。
- 集群路由：由集群实现分片路由，客户端连接任意节点，如果该节点存在请求的分片，则处理；否则将请求转发到合适的节点或者告诉客户端重定向到目标节点，如redis cluster
 
客户端路由实现相对简单，但是对业务入侵较强；代理层路由对业务透明，但增加了一层网络传输，对性能有一定影响，同时在部署上也相对复杂；集群路由对业务透明，比代理路由少了一层结构，节约成本，但实现更复杂，且不合理的策略会增加多次网络传输。

#### 动态平衡
导致分布式存储出现不平衡的因素：
- 读写负载增加，需要更多的CPU
- 数据规模增加，需要更多磁盘和内存
- 数据节点故障，需要其他节点接替

解决的办法，如redis cluster的resharding，HDFS/kafka的rebalance
- 固定分区创建远超节点数的分区数，为每个节点分配多个分区。如果有新增节点，可从现有的节点上均匀移走几个分区，从而达到平衡。可以采用如一致性哈希。分区数少，再平衡代价比较大，分区数多，则有一定的管理开销
- 动态分区自动增减分区数：当分区数据增长到一定阈值时，则对分区进行拆分。当分区数据缩小到一定阈值时，对分区进行合并，类似于B+树的分裂删除操作，同样的HBase Region的拆分合并，TDSQL的Set Shard。但是刚上线时，初始化分区为一个，可能压力比较大，所以可以采用HBase的预分类。

#### 分库分表
分库分表的使用情况：
- 单表的数据量达到了一定的量级，读写的性能会下降，索引也会很大，性能不佳，需要分解单表。
- 数据库吞吐量达到瓶颈，需要增加实例来分担数据库读写的压力。

分库分表的方式
- 垂直切分：按照一定的规则，如业务或模块类型，将一个数据库中的多个表分布到不同的数据库上，如在直播平台上，将直播节目数据、视频点播数据、用户关注数据分别存储在不同的数据库上
    - 优点：
         - 切分规则清楚，业务划分明确
         - 可以单找业务的类型、重要的程度进行成本管理，扩展也方便
         - 数据维护简单
    
    - 缺点：
        - 不同表在不同的库中，无法使用表连接jion。在实际的业务中，一般会建立映射表，通过两次查询或者写时构造好数据存到性能更高的存储系统中
        - 事务处理复杂，可以采用柔性事务或其他分布式事务方案
- 水平切分：按照一定规则，如哈希或者取模，将同一个表中的数据拆分到多个数据库上。
    - 优点
        - 切分后的表结构一样，业务代码不需要改动
        - 能控制单表数据量，有利于性能提升
    - 缺点
        - join、count、记录合并、排序、分页等问题需要跨节点处理
        - 相对复杂需要实现路由策略

#### 任务分片
将一个任务分成多个子任务并行处理

## 存储
每个系统的业务特性都不一样，有的侧重读，有的侧重写，有的两者兼备

#### 读写分离
大多数业务系统都是读多写少，为了提高系统的处理能力，可以采用读写分离的方式将主节点用于写，从节点用于读。读写分离架构有以下几个特点：
- 数据库为主从架构，可以为一主一从或者一主多从
- 主节点负责写操作，从节点负责读操作
- 主节点将数据复制到从节点，由主主从，主匆匆，也可以是mysql + redis

读写分离的主从架构一般采用异步复制，会存在数据复制延迟的问题，适用于对数据一致性要求不高的业务，解决复制滞后问题的方法有：
- 写后读一致性：即读自己的写，适用于用户写操作后要求实时看到更新。典型的场景是，用户注册或者修改账户密码后，紧接着登录。可以将用户的读请求发送到主节点上，查看其他用户信息的请求发送到从节点上。
- 二次读取：优先读取从节点，如果读取失败或者跟踪的更新时间小于某个阈值，则再从主节点读取
- 关键业务读取主节点，非关键业务读写分离
- 单调读：保证用户的读请求都发到同一个从节点。

#### 动静分离
将经常更新的数据和更新频率低的数据进行分离。在数据库中，动静分离更像是一种垂直切分，将动态和静态的字段分别存储在不同的库表中，减小数据库锁的粒度，同时可以分配不同的数据库资源来合理提升利用率。

#### 冷热分离
冷热分离可以说是每个存储产品和海量业务的必备功能，Mysql、ElasticSearch、CMEM、Grocery 等都直接或间接支持冷热分离。将热数据放到性能更好的存储设备上，冷数据下沉到廉价的磁盘

#### 重写轻读
- 关键写，降低读的关键性，如异步复制，保证主节点写成功即可，从节点的读可容忍同步延迟
- 写重逻辑，读轻逻辑，将计算的逻辑从读转移到写。适用于读请求的时候还要进行计算的场景，常见的如排行榜是在写的时候构建而不是在读请求的时候再构建。

朋友圈中，每个用户有一个对应的信箱。用户发完朋友圈后，写完自己的信箱就返回，然后异步的将消息推送到其朋友的信箱，这样朋友读取他的信箱时就是其朋友圈的消息列表。

#### 数据异构
数据异构主要是按照不同的维度建立索引关系以加速查询。如京东、天猫等网上商城，一般按照订单号进行了分库分表。由于订单号不在同一个表中，要查询一个买家或者商家的订单列表，就需要查询所有分库然后进行数据聚合。可以采取构建异构索引，在生成订单的时同时创建买家和商家到订单的索引表，这个表可以按照用户 id 进行分库分表。

## 队列
#### 异步处理
业务请求的处理流程通常很多，有些流程并不需要在本次请求中立即处理，这时就可以采用异步处理。如直播平台中，主播开播后需要给粉丝发送开播通知，可以将开播事件写入到消息队列中，然后由专门的 daemon来处理发送开播通知，从而提高开播的响应速度。

#### 流量削峰
高并发系统的性能瓶颈一般在 I/O 操作上，如读写数据库。面对突发的流量，可以使用消息队列进行排队缓冲。以企鹅电竞为例，每隔一段时间就会有大主播入驻，如梦泪等。这个时候会有大量用户的订阅主播，订阅的流程需要进行多个写操作，这时先只写用户关注了哪个主播存储。然后在进入消息队列暂存，后续再写主播被谁关注和其他存储。

#### 系统解耦
有些基础服务被很多其他服务依赖，如企鹅电竞的搜索、推荐等系统需要开播事件。而开播服务本身并不关心谁需要这些数据，只需处理开播的事情就行了，依赖服务（包括第一点说的发送开播通知的 daemon）可以订阅开播事件的消息队列进行解耦

#### 数据同步
消息队列可以起到数据总线的作用，特别是在跨系统进行数据同步时。拿我以前参与过开发的一个分布式缓存系统为例，通过 RabbitMQ 在写 Mysql 时将数据同步到Redis，从而实现一个最终一致性的分布式缓存。

#### 柔性事务
传统的分布式事务采用两阶段协议或者其优化变种实现，当事务执行时都需要争抢锁资源和等待，在高并发场景下会严重降低系统的性能和吞吐量，甚至出现死锁。互联网的核心是高并发和高可用，一般将传统的事务问题转换为柔性事务。下图是阿里基于消息队列的一种分布式事务实现
- 分布式事务发起方在执行第一个本地事务前，向 MQ 发送一条事务消息并保存到服务端，MQ 消费者无法感知和消费该消息（发送消息，消息发送成功）
- 事务消息返送成功后开始执行单机事务操作（执行本地事务）
- 如果本地事务执行成功，则将MQ服务端的事务消息更新为正常（commit OR rollback）
- 如果本地事务执行时因为宕机或者网络问题，没有及时向MQ服务端反馈，则之前的事务消息会一直保存在MQ。MQ服务端会对事务消息进行定期扫描，如果发现有消息保存时间超过了阈值，则向MQ生产端发送检察事务执行状态的请求
- 检查本地事务结果后，如果事务执行成功，则将之前保存的事务消息更新为正常状态，否则MQ服务端进行丢弃
- 消费者获取到事务消息设置为正常状态后，则执行第二个本地事务。如果执行失败，则通知MQ发送方对第一个本地事务进行回滚或正常补偿。