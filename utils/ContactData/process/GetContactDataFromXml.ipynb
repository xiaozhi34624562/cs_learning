{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xmltodict\n",
    "import json\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# everytime read 5 000 000 lines of xml file and transfer it to json(dictionsry)\n",
    "num = 0\n",
    "count = 0\n",
    "inside = []\n",
    "name = \"./data/output_event_\"\n",
    "with open(\"./output_events.xml\", 'rt') as f:\n",
    "    a = f.readline()\n",
    "    b = f.readline()\n",
    "    for line in f.readlines():\n",
    "        inside.append(line)\n",
    "        num += 1\n",
    "        if num % 5000000 == 0:\n",
    "            count += 1\n",
    "            xml = []\n",
    "            xml.append(a)\n",
    "            xml.append(b)\n",
    "            xml.extend(inside)\n",
    "            if inside[-1] != \"</events>\":\n",
    "                xml.append(\"</events>\")\n",
    "            xml_file = ''.join(xml)\n",
    "            js = xmltodict.parse(xml_file, encoding='utf-8')\n",
    "            file_name = name + str(count) + \"_\" + str(num) + \".json\"\n",
    "            with open(file_name, 'w') as fw:\n",
    "                json.dump(js, fw)\n",
    "            inside = []\n",
    "            del js, xml_file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The last time transforming may not be 5 000 000, it is needed to be dealed separately\n",
    "count += 1\n",
    "xml = []\n",
    "xml.append(a)\n",
    "xml.append(b)\n",
    "xml.extend(inside)\n",
    "if inside[-1] != \"</events>\":\n",
    "    xml.append(\"</events>\")\n",
    "xml_file = ''.join(xml)\n",
    "js = xmltodict.parse(xml_file, encoding='utf-8')\n",
    "file_name = name + str(count) + \"_\" + str(num) + \".json\"\n",
    "with open(file_name, 'w') as fw:\n",
    "    json.dump(js, fw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all the output_event.json file name and remove .DS_Store file which is automately created by Mac OS\n",
    "events = os.listdir(\"./data\")\n",
    "events.remove(\".DS_Store\")\n",
    "ordered_events = [0] * len(events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# order the event \n",
    "for event in events:\n",
    "    idx = int(event.split(\"_\")[2]) - 1\n",
    "    ordered_events[idx] = event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read all event by json form into memory\n",
    "eventList = []\n",
    "for event in ordered_events:\n",
    "    path = \"./data/\" + event\n",
    "    with open(path, 'r') as f:\n",
    "        json_event = json.load(f)\n",
    "    eventList.extend(json_event[\"events\"][\"event\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-process data(remove all the public transportation dataset)\n",
    "# event is recorded in this form {{\"time1\":time1, \"personId\":person, \"linkId\":\"link\"}, ...}\n",
    "eventsWithoutPublic = []\n",
    "for item in eventList:\n",
    "    if item.__contains__(\"@link\"):\n",
    "        if item.__contains__(\"@person\"): \n",
    "            if not item[\"@person\"].startswith(\"pt\"):\n",
    "                eventsWithoutPublic.append({\"time\":float(item[\"@time\"]), \"person\":item[\"@person\"], \"link\":item[\"@link\"]})\n",
    "        else:\n",
    "            if item.__contains__(\"@vehicle\"):\n",
    "                if not item[\"@vehicle\"].startswith(\"pt\"):\n",
    "                    eventsWithoutPublic.append({\"time\":float(item[\"@time\"]), \"person\":item[\"@vehicle\"], \"link\":item[\"@link\"]})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store event_without_public.json file\n",
    "with open(\"event_without_public.json\", 'w') as ewp:\n",
    "    json.dump(eventsWithoutPublic, ewp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load event_without_public.json file\n",
    "with open(\"./event_without_public.json\", 'r') as fr:\n",
    "    eventsWithoutPublic = json.load(fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide the event \n",
    "quarter = int(len(eventsWithoutPublic) / 4)\n",
    "eventsWithoutPublic_first = eventsWithoutPublic[:quarter]\n",
    "eventsWithoutPublic_second = eventsWithoutPublic[quarter : quarter * 2]\n",
    "eventsWithoutPublic_third = eventsWithoutPublic[quarter*2 : quarter * 3]\n",
    "eventsWithoutPublic_fourth = eventsWithoutPublic[quarter*3 :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sorted_event_by_link(events):\n",
    "    # sort data into links\n",
    "    #  data form is {\"link1\" : {time1 : {\"person1\", \"person2\", ...} ... }, ...}\n",
    "    linkDict = {}\n",
    "    e = 0\n",
    "    for item in events:\n",
    "        e += 1\n",
    "        if linkDict.__contains__(item[\"link\"]):\n",
    "            if linkDict[item[\"link\"]].__contains__(item[\"time\"]):\n",
    "                (linkDict[item[\"link\"]][item[\"time\"]]).add(item[\"person\"])\n",
    "            else:\n",
    "                linkDict[item[\"link\"]][item[\"time\"]] = {item[\"person\"]}\n",
    "        else:\n",
    "            linkDict[item[\"link\"]] = {item[\"time\"] : {item[\"person\"]}}\n",
    "        if e % 10000000 == 0:\n",
    "            print(e)\n",
    "    del events\n",
    "    return linkDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linkDict = sorted_event_by_link(eventsWithoutPublic_first)\n",
    "with open(\"./link_first.pkl\", 'wb') as fsw:\n",
    "    pickle.dump(linkDict, fsw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linkDict = sorted_event_by_link(eventsWithoutPublic_second)\n",
    "with open(\"./link_secong.pkl\", 'wb') as fsw:\n",
    "    pickle.dump(linkDict, fsw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linkDict = sorted_event_by_link(eventsWithoutPublic_third)\n",
    "with open(\"./link_third.pkl\", 'wb') as ftw:\n",
    "    pickle.dump(linkDict, ftw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linkDict = sorted_event_by_link(eventsWithoutPublic_fourth)\n",
    "with open(\"./link_fourth.pkl\", 'wb') as fw:\n",
    "    pickle.dump(linkDict, fw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"./link_fourth.pkl\", 'rb') as fr:\n",
    "#     b = pickle.load(fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./network.xml\", 'r') as fn:\n",
    "    network_xml = fn.read()\n",
    "    network = xmltodict.parse(network_xml, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network[\"network\"][\"links\"][\"link\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network[\"network\"][\"links\"][\"link\"][1][\"@id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "links = dict()\n",
    "for link in network[\"network\"][\"links\"][\"link\"]:\n",
    "    id = link[\"@id\"]\n",
    "    links[id] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(links.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"link_first.pkl\", \"rb\") as flf:\n",
    "    link_first = pickle.load(flf)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"link_second.pkl\", \"rb\") as fsf:\n",
    "    link_second = pickle.load(fsf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"link_third.pkl\", \"rb\") as ftf:\n",
    "    link_third = pickle.load(ftf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"link_fourth.pkl\", \"rb\") as fff:\n",
    "    link_fourth = pickle.load(fff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stride = int(len(links.keys()) / 10)\n",
    "# stride = 100\n",
    "links_key = list(links.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links_0 = {key: dict() for key in links_key[:stride]}\n",
    "links_1 = {key: dict() for key in links_key[stride : stride * 2]}\n",
    "links_2 = {key: dict() for key in links_key[stride * 2 : stride * 3]}\n",
    "links_3 = {key: dict() for key in links_key[stride * 3 : stride * 4]}\n",
    "links_4 = {key: dict() for key in links_key[stride * 4 : stride * 5]}\n",
    "links_5 = {key: dict() for key in links_key[stride * 5 : stride * 6]}\n",
    "links_6 = {key: dict() for key in links_key[stride * 6 : stride * 7]}\n",
    "links_7 = {key: dict() for key in links_key[stride * 7 : stride * 8]}\n",
    "links_8 = {key: dict() for key in links_key[stride * 8 : stride * 9]}\n",
    "links_9 = {key: dict() for key in links_key[stride * 9 :]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_dict_all = [link_first, link_second, link_third, link_fourth]\n",
    "link_target_all = [links_0, links_1, links_2, links_3, links_4, links_5, links_6, links_7, links_8, links_9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(links_0.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "for link_target in link_target_all:\n",
    "    for key, val in link_target.items():\n",
    "        for link_dict in link_dict_all:\n",
    "            if link_dict.__contains__(key):\n",
    "                for time, person in link_dict[key].items():\n",
    "                    if link_target[key] is not None and link_target[key].__contains__(time):\n",
    "                        link_target[key][time].update(person)\n",
    "                    else:\n",
    "                        link_target[key][time] = person\n",
    "        print(\"choose one from four\")\n",
    "    file_name = \"link_\" + str(idx) + \".pkl\"\n",
    "    print(\"the \" + str(idx) + \" link file begin to store\")\n",
    "    with open(file_name, \"wb\") as link_file:\n",
    "        pickle.dump(link_target, link_file)\n",
    "    print(\"the \" + str(idx) + \" link file stored\")\n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"link_0.pkl\", 'rb') as fr0:\n",
    "    l_0 = pickle.load(fr0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(l_0.keys())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 0\n",
    "for k, v in l_0.items():\n",
    "    for i,j in l_0[k].items():\n",
    "        if len(j) >= 3:\n",
    "            num +=1\n",
    "num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the contact data\n",
    "# {'person1':{'person1':'n1', 'person2':'n2', 'person3':'n3'}, 'person2':{...}}\n",
    "\n",
    "def contact(linkDict, personContact, stride):\n",
    "    # stride = 500\n",
    "    # v {0.0: {'95187201', '123413'}, 3597.0: {'95187201'}, 25549.0: {'322233201'} \n",
    "    # {time:{person}}\n",
    "    for k, v in linkDict.items():\n",
    "        # {0.0, 3597.0}\n",
    "        times = list(v.keys())\n",
    "        # diff = list(map(lambda x : abs(x[1] - x[0]), zip(times[:-1], times[1:])))\n",
    "        for t1 in range(len(times)):\n",
    "            for t2 in range(1, len(times)):\n",
    "                if abs(times[t2] - times[t1]) <= stride:\n",
    "                    mPersons = list(linkDict[k][times[t1]])\n",
    "                    cPerson = list(linkDict[k][times[t2]])\n",
    "                    for p in mPersons:\n",
    "                        for cp in cPerson:\n",
    "                            if p == cp:\n",
    "                                continue\n",
    "                            if not personContact.__contains__(p):\n",
    "                                personContact[p] = dict()\n",
    "                                if not personContact[p].__contains__(cp):\n",
    "                                    personContact[p][cp] = 0\n",
    "                                else:\n",
    "                                    num = personContact[p][cp] + 1\n",
    "                                    personContact[p][cp] = num\n",
    "                            else:\n",
    "                                if not personContact[p].__contains__(cp):\n",
    "                                    personContact[p][cp] = 0\n",
    "                                else:\n",
    "                                    num = personContact[p][cp] + 1\n",
    "                                    personContact[p][cp] = num\n",
    "                else:\n",
    "                    break\n",
    "    return personContact\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = \"../event_sorted_by_link/\"\n",
    "link_pkl_list = os.listdir(dir)\n",
    "personContact = dict()\n",
    "stride = 500\n",
    "idx = 0\n",
    "\n",
    "for file in link_pkl_list:\n",
    "    print('begin to load data')\n",
    "    with open(dir + file, \"rb\") as fr:\n",
    "        linkDict = pickle.load(fr)\n",
    "    print(\"begin to get contact data\")\n",
    "    personContact = contact(linkDict, personContact, stride)\n",
    "    print(\"get the contact data in link \" + str(idx))\n",
    "    idx += 1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../contact_data.pkl\", 'wb') as fwb:\n",
    "    pickle.dump(personContact, fwb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(personContact.keys())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3dd4805aa1ae2fd696697ada0dc0651f48bcaf601d176aa13c8e36d838f7eab8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
